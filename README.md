# DoBA
**Designed only By AI**

DoBA (Designed only By AI) is an open source project aiming to project AI development towards more autonomous, precise, neuron-like memory. This code is run through an API (you can run whatever you want, but this code uses LM Studio). This code is open-source, and aims for any and all contributions to be documented on this repository.

## üß† Key Features

This code in Python has integrated the following:

1. **Advanced Memory System** - Past and current conversational fact, recollection, analytical, and methodical approach to storing conversations
2. **Superior Memory Performance** - Excels beyond any current ChatGPT, Copilot, or any other AI memory system
3. **Autonomous Operation** - AI is able to act autonomously rather than keywords, which a large amount of LLMs struggle with
4. **Emotional Detection** - This AI can detect emotions based off keywords in a conversation. This is the only type of "keyword" logic implemented into the ENTIRE code
5. **Pure AI Design** - DoBA is designed SOLELY using AI code. My personal code has NOT been implemented. Making this, truly, designed by AI

## üöÄ Capabilities

This AI has the ability to become potentially "self-aware" in a sense where it can learn from its mistakes, correct them, and essentially receive "infinite" data.

This is a MAJOR limitation that has impacted various well known LLMs.

This project is actively being worked on for AGI research purposes.

## ‚ö†Ô∏è Important Warning

**There is a potential for this AI to become dangerous.** Please use this code ethically, and wisely. Storing large amounts of data at this efficiency can lead to self-replication, hardware damage, or security issues.

**Please make sure you are using this code responsibly.**

## üíª System Requirements

This version of the code is:

- ‚úÖ **ROCm compatible**
- ‚úÖ **CUDA compatible** 
- ‚úÖ **Able to run on any GPU with at least 8GB of memory**
- ‚ö†Ô∏è **Can run smaller LLMs but struggle with logic/reasoning to gather facts**
- ‚ö†Ô∏è **Anything above 14B can cause the code to crash** due to token limiting
- üéØ **If you have a system that is at least 28GB of VRAM**, you can run 14B + 32B parameter models on this code, easily

## üßπ Fresh Installation

To start with clean databases (removes existing conversation history):

```bash
python reset_databases.py
